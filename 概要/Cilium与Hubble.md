# Cilium与Hubble

## Cilium

Cilium是一个开源软件，旨在对应用服务间的网络连接进行透明加固，这些应用服务都是用Docker或者Kubernetes这种Linux容器管理平台部署的。

Cilium的技术底座就是所谓的eBPF，它能够动态的插入强大的安全观测能力和控制逻辑到Linux自身当中。由于eBPF是运行在Linux内核之中，Cilium可以对应用代码和容器配置无感知的情况下进行应用和更新。

## Hubble

[Hubble](../可观测性/使用Hubble进行网络观测.md)是一个分布式的网络和安全观测平台。它构建在Cilium和eBPF之上，对于服务和网络设施间的通信和行为，带来深度的可观测性，而且完全透明。

有了Cilium，Hubble就可以利用eBPF实现观测。有了eBPF，所有的观测都是可编程的，通过动态行为提供深入且详细的观测，同时还能最小化带来的损耗，满足用户需求。Hubble创建之初就是要尽全力发挥出eBPF的能力。

有了Hubble就可以回答下面的问题：

### 服务间的依赖与通信

- 哪些服务在相互通信？有多频繁？服务依赖关系图是怎样的？
- 发起了怎样的HTTP请求？一个服务消费或发出了哪些Kafka topic的消息？

### 网络监控与告警

- 是否有网络异常发生？为什么异常？是DNS的问题吗？还是程序或网络的问题？问题出在4层还是7层？
- 过去5分钟内哪些服务遇到了DNS解析的问题？最近有哪些服务遇到了TCP连接中断或超时的问题？未响应的TCP SYN请求频率是多少？

### 应用监控

- 某个服务或整个集群的HTTP 4xx或5xx的频率是多少？
- 在我的集群中，HTTP请求和响应延迟的95和99百分位是多少？哪些服务最慢？某两个服务之间的延迟是多少？

### 安全可观测性

- 哪些服务由于网络策略导致连接被阻断？哪些服务被集群外部访问？某个DNS名称被哪些服务解析了？

## 为什么选择Cilium+Hubble？

eBPF为系统和程序带来的可见性和控制力，这种粒度和效率都是前所未有的。它以完全透明的方式进行，不需要应用程序做任何改动。对于现代的容器化应用，以及传统的虚拟机应用或标准的Linux进程，eBPF都能够实现完全相同的功能。

现代数据中心应用的发展已经转向到SOA架构，也就是常说的*微服务*，把以前的一个大应用拆成了多个小的独立应用，通过HTTP等轻量级协议相互通信。微服务的应用通常是变化非常快的，各自有独立的容器，随着负载的变化以及不断地持续部署更新，这些应用会不断地启动和销毁。

这种快速迭代的微服务，对于微服务间的安全连接带来了机遇和挑战。传统的Linux网络安全措施（比如iptables）是根据IP地址和TCP/UDP端口进行过滤，但在微服务环境中IP地址总是在不停的变化。容器的这种短生命周期导致传统方法难以跟上脚步，随着变化频率不断的增加，包含有上千条记录的负载均衡清单以及控制清单都要不断更新。协议端口（比如HTTP用80）已经不再能从安全的角度作为区分不同应用流量的方法，因为这些端口如今在各个服务上可能用于不同的用途。

另一个挑战是如何提供准确的可见性，以前的系统中往往使用IP作为主要的身份标识，但在微服务架构中可能仅存在几秒钟就消失了。

基于Linux eBPF，Cilium保留了透明插入安全可见性及策略的能力，而且还能以service/pod/container作为身份标识（相对于传统的IP地址），还能在7层网络上进行过滤（比如HTTP）。最终，Cilium不光能以极简的形式在高度变化的环境中设置安全策略，将安全与寻址相解耦，而且在提供传统3、4层网络隔离能力的基础上还能在HTTP层上进行操作，提供了更强的安全隔离。

有了eBPF，Cilium就能以高度的伸缩性实现以上的各种能力，即便是在大规模环境中。

## 功能一览

### 透明的API防御加固

能够对现代应用协议进行加固的能力，比如REST/HTTP、gRPC、Kafka。传统防火墙工作在3和4层网络。某个端口上的协议要么完全信任要么完全阻断。Cilium可以对每个应用协议请求进行过滤：

- 放行所有HTTP`GET`请求和`/public/.*`的请求。拒绝其他请求。
- 允许`service1`向Kafka的`topic1`主题发送消息，允许`service2`消费`topic1`主题的消息。
- 对于所有的REST请求，必须携带HTTP header`X-Token: [0-9]+`。

最新的可支持协议列表及用例见[7层网络策略示例](../安全/网络策略/3层网络示例.md#7层网络示例)。

### 根据身份加固服务间通信

现在的应用都采用容器技术来提升部署的灵活性，满足按需扩缩的需求。这就导致短时间内可能会启动大量的容器。传统的容器防火墙是根据源IP和目标端口对应用进行加固。这种方式就会导致无论哪台服务器上起了一个容器，所有服务器上的防火墙都要进行调整。

为了避免这种影响伸缩性的问题出现，Cilium给多组容器应用赋予同一个安全身份，让它们共享同样的安全策略。这个身份会附加到所有由这些容器发出的网络数据包上，在接收端就可以进行身份的验证。安全身份管理是采用一种kv存储的方式来进行的。

### 加固外部服务往来

基于标签的安全措施用于集群内部的访问控制。对于外部服务的往来，支持传统的CIDR安全策略。这就可以实现对特定IP返回的往来通信控制。

### 简单的网络

以一种简单的平铺的3层网络可以将多个集群上的所有容器连接在一起。IP分配只需在每个主机上自行完成。也就是说每个主机自行分配IP而无需互相沟通。

支持以下多节点网络模型：

- **Overlay：**采用封装思想的多节点虚拟网络。目前已内置VXLAN和Geneve，但Linux可用的所有封装格式都能用。

    何时采用这种方案：这种模式对基建和集成的需求最小。几乎所有网络设施下都能用，只需要IP层的连通性，而这基本上都是已经支持了的。

- **原生路由：**利用Linux主机的常规路由表。网络中需要有能力对应用容器的IP地址进行路由。

    何时采用这种方案：这是高级用户的玩具，需要了解底层网络基建。这种模式可以很好的处理：

    - 原生IPv6网络
    - 与云上网络路由协作
    - 已有路由设备
